{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\vedyon\\langchain_env\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\vedyon\\langchain_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\vedyon\\langchain_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "\n",
    "llm = ChatOllama(model=\"qwen2.5:7b\")\n",
    "\n",
    "# repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# llm = HuggingFaceEndpoint(repo_id=repo_id, max_length=150, temperature=0.7, token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "# Use HuggingFace's MiniLM embeddings (384 dimensions)\n",
    "# embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()\n",
    "\n",
    "review_compression_prompt = \"\"\" \n",
    "Give sentiment and themes for the given input reviews.\n",
    "Give output as json with 'sentiment' key and value should be either of [POSITIVE, NEGATIVE, NEUTRAL].\n",
    "and another key 'theme' with list of themes talked about in the reviews, for example 'product issue', 'packing issues' etc...\n",
    "\n",
    "Strictly only give JSON output as a string and nothing else. Do not use markdown.\n",
    "\n",
    "Input reviews:\n",
    "``` {input_review} ```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Give sentiment and themes for the given input reviews.\n",
      "Give output as json with 'sentiment' key and value should be either of [POSITIVE, NEGATIVE, NEUTRAL].\n",
      "and another key 'theme' with list of theses talked about in the rviews, for example 'product issue', 'packing issues' etc...\n",
      "\n",
      "strickly only give json output as strings and another nothing else. Do not give markdown.\n",
      "\n",
      "input reviews:\n",
      "``` this is the bedsheet is beatuful and looks just like ain the picture. The print is very pretty, it is really comfortable ad smooth ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_review = \"this is the bedsheet is beatuful and looks just like ain the picture. The print is very pretty, it is really comfortable ad smooth\"\n",
    "\n",
    "promt_temp = PromptTemplate(template = review_compression_prompt, input_variables=[\"input_review\"])\n",
    "\n",
    "# input_prompt = promt_temp.invoke({'input_review': input_review})\n",
    "# print(input_prompt.text)\n",
    "\n",
    "formatted_prompt = promt_temp.format(input_review=input_review)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = promt_temp | llm | parser\n",
    "# result = chain.invoke({ input_review:\"input_review\"})\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sentiment\":\"POSITIVE\",\"theme\":[\"appearance\",\"comfort\"]}\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(formatted_prompt)\n",
    "compressed_review = parser.invoke(result)\n",
    "\n",
    "print(compressed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Sentiment(str, Enum):\n",
    "#     positive = \"POSITIVE\",\n",
    "#     negative = \"NEGATIVE\",\n",
    "#     neutral = \"NEUTRAL\",\n",
    "\n",
    "# class compresed_review(BaseModel):\n",
    "#     sentiment : Sentiment = Field(description=\"Gives sentiment value of the review\")\n",
    "#     theme: list = Field(description=\"theme expressed in the reviews\")\n",
    "\n",
    "# Define sentiment Enum properly\n",
    "class Sentiment(str, Enum):\n",
    "    positive = \"POSITIVE\"\n",
    "    negative = \"NEGATIVE\"\n",
    "    neutral = \"NEUTRAL\"\n",
    "\n",
    "# Define the compressed review model\n",
    "class CompressedReview(BaseModel):\n",
    "    sentiment: Sentiment = Field(description=\"Gives sentiment value of the review\")\n",
    "    theme: list = Field(description=\"Themes expressed in the reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_json = JsonOutputParser(pydantic_object=CompressedReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = PromptTemplate(\n",
    "#     template = \"Gives sentiment and theme for a reviews. \\n {format_instructions} \\n {input_review}\",\n",
    "#     input_variable = ['input_review'],\n",
    "#     partial_variables={\"format_instructions\": parser_json.get_format_instructions()},\n",
    "# )\n",
    "\n",
    "# Define the prompt correctly\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Gives sentiment and theme for a review. \\n{format_instructions} \\n{input_review}\",\n",
    "    input_variables=[\"input_review\"],\n",
    "    partial_variables={\"format_instructions\": parser_json.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Sentiment\": {\"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"], \"title\": \"Sentiment\", \"type\": \"string\"}}, \"properties\": {\"sentiment\": {\"$ref\": \"#/$defs/Sentiment\", \"description\": \"Gives sentiment value of the review\"}, \"theme\": {\"description\": \"Themes expressed in the reviews\", \"items\": {}, \"title\": \"Theme\", \"type\": \"array\"}}, \"required\": [\"sentiment\", \"theme\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser_json.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gives sentiment and theme for a review. \n",
      "Return a JSON object. \n",
      "this is the bedsheet is beatuful and looks just like ain the picture. The print is very pretty, it is really comfortable ad smooth\n"
     ]
    }
   ],
   "source": [
    "input_review = \"this is the bedsheet is beatuful and looks just like ain the picture. The print is very pretty, it is really comfortable ad smooth\"\n",
    "\n",
    "formatted_prompt = prompt.invoke({'input_review': input_review})\n",
    "print(formatted_prompt.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(formatted_prompt)\n",
    "compresed_review = parser_json.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'Positive', 'theme': ['Appearance', 'Comfort', 'Quality']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compresed_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_json = JsonOutputParser()\n",
    "\n",
    "# Define the prompt correctly\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Gives sentiment and theme for a review. \\n{format_instructions} \\n{input_review}\",\n",
    "    input_variables=[\"input_review\"],\n",
    "    partial_variables={\"format_instructions\": parser_json.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'Neutral', 'theme': 'Joke about scientists and atoms'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | parser_json\n",
    "review = \"Why don't scientists trust atoms? Because they make up everything\"\n",
    "chain.invoke({'input_review': review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
